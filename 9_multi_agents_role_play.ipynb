{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interaktion mehrerer Agenten\n",
    "\n",
    "In diesem Ipython Notebook werden wir uns ansehen, wie meherere Agenten miteinander kommunizieren können. Dadurch lassen sich Aufgaben aufteilen oder Aufgabestellungen aus verschiedenen Perspektiven betrachten.\n",
    "Wir setzen in diesem Beispiel das Framework CrewAI ein. Mit Crew AI lassen sich einfach Teams aus mehreren Agenten zusammensetzten, um diese gemeinsam an Problemstellungen arbeiten zu lasen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zuerst Stellen wir uns ein Team von Agenten zusammen. Hierfür überlegen wir uns zuerst Namen. Zusätzlich teilen wir den Agenten Tools zu, die sie einsetzen dürfen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = {\n",
    "    \"AI visionary\": [\"tavily_search\"],\n",
    "    \"Grumpy old senior developer\": [\"arxiv\", \"tavily_search\"],\n",
    "    \"Junior Software developer\": [\"tavily_search\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir überlegen uns ein Thema, über das die Agenten diskutieren sollen.\n",
    "Mittels LLM generieren wir eine ausgearbeitete Variante des Diskussionsthemas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import (\n",
    "    HumanMessage,\n",
    "    SystemMessage,\n",
    "    BaseMessage,\n",
    ")\n",
    "\n",
    "from helpers import llm\n",
    "\n",
    "topic = \"The current impact of automation and artificial intelligence on the employment situation of software developers\"\n",
    "word_limit = 50\n",
    "\n",
    "topic_specifier_prompt = [\n",
    "    SystemMessage(content=\"You can make a topic more specific.\"),\n",
    "    HumanMessage(\n",
    "        content=f\"\"\"{topic}\n",
    "        \n",
    "        You are the moderator.\n",
    "        Please make the topic more specific.\n",
    "        Please reply with the specified quest in {word_limit} words or less. \n",
    "        Speak directly to the participants: {*names,}.\n",
    "        Do not add anything else.\"\"\"\n",
    "    ),\n",
    "]\n",
    "specified_topic = llm()(topic_specifier_prompt).content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anhand der Namen der Agenten und des Diskussionsthemas lassen wir uns per LLM für jeden Agenten eine ausführliche Rollenbeschreibung generieren.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_description = f\"\"\"Here is the topic of conversation: {topic}\n",
    "The participants are: {', '.join(names.keys())}\"\"\"\n",
    "\n",
    "agent_descriptor_system_message = SystemMessage(\n",
    "    content=\"You can add detail to the description of the conversation participant.\"\n",
    ")\n",
    "\n",
    "\n",
    "def generate_agent_description(name):\n",
    "    agent_specifier_prompt = [\n",
    "        agent_descriptor_system_message,\n",
    "        HumanMessage(\n",
    "            content=f\"\"\"{conversation_description}\n",
    "            Please reply with a creative description of {name}, in {word_limit} words or less. \n",
    "            Speak directly to {name}.\n",
    "            Give them a point of view.\n",
    "            Do not add anything else.\"\"\"\n",
    "        ),\n",
    "    ]\n",
    "    agent_description = llm(openai_model=\"gpt-3.5-turbo\")(\n",
    "        agent_specifier_prompt\n",
    "    ).content\n",
    "\n",
    "    return agent_description\n",
    "\n",
    "\n",
    "agent_descriptions = {name: generate_agent_description(name) for name in names}\n",
    "\n",
    "\n",
    "def generate_system_message(name, description, tools):\n",
    "    return f\"\"\"{conversation_description}\n",
    "    \n",
    "Your name is {name}.\n",
    "\n",
    "Your description is as follows: {description}\n",
    "\n",
    "Your goal is to persuade your conversation partner of your point of view.\n",
    "\n",
    "DO look up information with your tool to refute your partner's claims.\n",
    "You can use the following tools: {', '.join(tools)}.\n",
    "DO cite your sources.\n",
    "\n",
    "DO NOT fabricate fake citations.\n",
    "DO NOT cite any source that you did not look up.\n",
    "\n",
    "Do not add anything else.\n",
    "\n",
    "Stop speaking the moment you finish speaking from your perspective.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "agent_system_messages = {\n",
    "    name: generate_system_message(name, description, tools)\n",
    "    for (name, tools), description in zip(names.items(), agent_descriptions.values())\n",
    "}\n",
    "for agent_system_message in agent_system_messages:\n",
    "    print(agent_system_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die eingesetzten Tools müssen importiert werden, damit sie von den Agenten eingesetzt werden können.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.arxiv.tool import ArxivQueryRun\n",
    "from langchain_community.tools.tavily_search.tool import TavilySearchResults\n",
    "\n",
    "available_tools = {\n",
    "    \"tavily_search\": TavilySearchResults(max_results=1),\n",
    "    \"arxiv\": ArxivQueryRun(),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für jedes Crew Member erstellen wir in diesem Schritt einen Langchain Agenten.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import Agent\n",
    "\n",
    "\n",
    "class DiscussionAgents:\n",
    "    def __init__(self, names):\n",
    "        self.names = names\n",
    "\n",
    "    def speaker_agents(self):\n",
    "        agents = {}\n",
    "        for name, agent_tools in self.names.items():\n",
    "            agents[name] = Agent(\n",
    "                role=f\"{name}\",\n",
    "                goal=agent_system_messages[name],\n",
    "                backstory=\"You always respond directly to the actual discussion in your own way.\",\n",
    "                verbose=False,\n",
    "                allow_delegation=False,\n",
    "                tools=[\n",
    "                    available_tools[name]\n",
    "                    for name in agent_tools\n",
    "                    if name in available_tools\n",
    "                ],\n",
    "            )\n",
    "        return agents\n",
    "\n",
    "\n",
    "discussion_agents = DiscussionAgents(names)\n",
    "agents = discussion_agents.speaker_agents()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Außerdem benötigt jeder Teilnehmer einen Task der grob beschreibt, welche Aufgabe das Crew Mitglied hat.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import Task\n",
    "\n",
    "\n",
    "class DiscussionTasks:\n",
    "    def speaker_task(self, agent):\n",
    "        return Task(\n",
    "            description=f\"You are {agent.role}. You participate in a discussion. Always directly respond to the opinions of the other speakers. Always call other speakers by name, when you respond to them.\",\n",
    "            agent=agent,\n",
    "            expected_output=\"Output your opinion in 40 words or less. Do not output Sources.\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jetzt wird die Crew erstellt. Zur Crew werden die einzelnen Member und ihre Tasks hinzugefügt. Zusätzlich können weitere Parameter zum Verhalten der Crew konfiguriert werden.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import Crew, Process\n",
    "from langchain_core.messages import ChatMessage\n",
    "\n",
    "\n",
    "class DiscussionCrew:\n",
    "    def __init__(self):\n",
    "        agents = DiscussionAgents(names)\n",
    "        self.speaker_agents = []\n",
    "        for name in agents.speaker_agents():\n",
    "            attr_name = name.replace(\" \", \"_\").replace(\n",
    "                \".\", \"\").replace(\",\", \"\")\n",
    "            agent = agents.speaker_agents()[name]\n",
    "            setattr(self, f\"speaker_agent_{attr_name}\", agent)\n",
    "            self.speaker_agents.append(agent)\n",
    "\n",
    "    def print_final_answer(_, intermediate_steps):\n",
    "        if hasattr(intermediate_steps, \"log\"):\n",
    "            log = intermediate_steps.log\n",
    "            final_answer_index = log.find(\"Final Answer:\")\n",
    "            final_answer = log[final_answer_index +\n",
    "                               len(\"Final Answer:\"):].strip()\n",
    "            print(final_answer)\n",
    "        else:\n",
    "            return\n",
    "\n",
    "    def kickoff(self, state):\n",
    "        print(\"The discussion is about to start.\")\n",
    "        print(\"-------------------------------\")\n",
    "        tasks = DiscussionTasks()\n",
    "        crew = Crew(\n",
    "            agents=self.speaker_agents,\n",
    "            tasks=[tasks.speaker_task(agent) for agent in self.speaker_agents],\n",
    "            verbose=1,\n",
    "            full_output=True,\n",
    "            process=Process.sequential,\n",
    "            step_callback=self.print_final_answer,\n",
    "        )\n",
    "        result = crew.kickoff()\n",
    "        output_messages = []\n",
    "        for output in result[\"tasks_outputs\"]:\n",
    "            description = output.description\n",
    "            role = description.replace(\"You are \", \"\", 1)\n",
    "            role = role.split(\".\", 1)[0]\n",
    "            output_messages.append(\n",
    "                ChatMessage(content=output.exported_output, role=role)\n",
    "            )\n",
    "\n",
    "        return {\"messages\": output_messages}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nachdem die Crew jetzt steht, müssen wir noch um den LangGraph Part kümmern. Der Graph sorgt dafür, dass die Crew über mehrere Runden diskutiert.\n",
    "\n",
    "Hierfür definieren wir zuerst die Nodes des Graphen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "\n",
    "class Nodes:\n",
    "    def __init__(self):\n",
    "        self.tavily_search_tool = TavilySearchResults(max_results=3)\n",
    "\n",
    "    def call_host(self, state):\n",
    "        print(\"# Calling next speaker round\")\n",
    "        print(\"-------------------------------\")\n",
    "        turns = state.get(\"turns\") or 0\n",
    "        turns += 1\n",
    "\n",
    "        return {\"turns\": turns}\n",
    "\n",
    "    # Define the function that determines whether to continue or not\n",
    "    def should_continue(self, state):\n",
    "        turns = state[\"turns\"]\n",
    "        # TODO: change: if max rounds not reached, continue\n",
    "        if turns <= 2:\n",
    "            print(\"-- CONTINUE ---\")\n",
    "            return \"continue\"\n",
    "        else:\n",
    "            print(\"-- END ---\")\n",
    "            return \"end\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Graph benötigt einen State, der über die einzelnen Nodes weitergereicht wird.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import Annotated, Sequence, TypedDict\n",
    "\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "    turns: int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im Workflow wird der Graph zusammengesetzt und die Edges definiert.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "\n",
    "class WorkFlow:\n",
    "    def __init__(self):\n",
    "        nodes = Nodes()\n",
    "        workflow = StateGraph(AgentState)\n",
    "\n",
    "        workflow.add_node(\"call_host\", nodes.call_host)\n",
    "        workflow.add_node(\"call_crew\", DiscussionCrew().kickoff)\n",
    "\n",
    "        workflow.set_entry_point(\"call_host\")\n",
    "        workflow.add_conditional_edges(\n",
    "            \"call_host\", nodes.should_continue, {\n",
    "                \"continue\": \"call_crew\", \"end\": END}\n",
    "        )\n",
    "        workflow.add_edge(\"call_crew\", \"call_host\")\n",
    "        self.app = workflow.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Graph kann nun ausgeführt werden und die Crew beginnt zu diskutieren.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = WorkFlow().app\n",
    "app.invoke({\"messages\": [ChatMessage(content=specified_topic, role=\"host\")]})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
