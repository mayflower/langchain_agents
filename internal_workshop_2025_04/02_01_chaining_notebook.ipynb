{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chaining - Verketten von Anfragen und Modellen\n",
    "\n",
    "In diesem Notebook lernen wir das Konzept des Chainings in LangChain kennen. Chaining erlaubt uns die Verkettung mehrerer Komponenten für komplexe Workflow-Muster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import der benötigten Bibliotheken\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema import StrOutputParser\n",
    "from helpers import llm\n",
    "import asyncio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Grundlagen des Chainings\n",
    "\n",
    "Chaining ist ein grundlegendes Konzept in LangChain, bei dem verschiedene Komponenten miteinander verkettet werden, um Daten in einer Pipeline zu verarbeiten. Die LangChain Expression Language (LCEL) bietet eine elegante Syntax mit dem Pipe-Operator `|` für solche Verkettungen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versionskontrolle ist wichtig, da sie es ermöglicht, Änderungen im Code über die Zeit nachzuverfolgen und bei Bedarf zu früheren Versionen zurückzukehren, was die Fehlerbehebung erleichtert. Sie fördert die Zusammenarbeit im Team, indem sie es mehreren Entwicklern erlaubt, gleichzeitig an verschiedenen Teilen eines Projekts zu arbeiten, ohne sich gegenseitig zu behindern. Zudem bietet Versionskontrolle eine transparente Historie aller Änderungen, was die Nachvollziehbarkeit und Wartung des Codes erheblich verbessert.\n"
     ]
    }
   ],
   "source": [
    "# Ein einfaches Beispiel für Chaining\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Du bist ein hilfreicher Assistent für {beruf}.\"),\n",
    "    (\"human\", \"Erkläre in drei Sätzen, warum {thema} wichtig für Deine Tätigkeit ist.\")\n",
    "])\n",
    "\n",
    "# Einfache Chain mit Pipe-Operator\n",
    "chain = prompt | llm() | StrOutputParser()\n",
    "\n",
    "# Chain ausführen\n",
    "result = chain.invoke({\"beruf\": \"Programmierer\", \"thema\": \"Versionskontrolle\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Der Pipe-Operator und LCEL\n",
    "\n",
    "Der Pipe-Operator (`|`) ist das zentrale Element der LangChain Expression Language (LCEL). Er ermöglicht das Verketten von Komponenten auf intuitive Weise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mit Pipe-Operator:\n",
      " Empathie ist entscheidend, um die Bedürfnisse und Gefühle der Patienten besser zu verstehen und eine vertrauensvolle Beziehung aufzubauen. Sie ermöglicht es, individuell auf Patienten einzugehen und deren Sorgen ernst zu nehmen, was die Behandlungsergebnisse positiv beeinflussen kann. Zudem hilft Empathie dabei, die Kommunikation zwischen Arzt und Patient zu verbessern, wodurch Missverständnisse vermieden werden können.\n",
      "\n",
      "Ohne Pipe-Operator:\n",
      " Empathie ist für meine Tätigkeit als Arzt von zentraler Bedeutung, da sie es mir ermöglicht, die Gefühle und Bedürfnisse meiner Patienten besser zu verstehen und so eine vertrauensvolle Arzt-Patienten-Beziehung aufzubauen. Durch empathisches Zuhören kann ich genauer auf die individuellen Sorgen und Erwartungen eingehen, was die Diagnose und Behandlung verbessern kann. Zudem fördert Empathie die Patientenzufriedenheit und -bindung, was sich positiv auf den Heilungsprozess auswirken kann.\n"
     ]
    }
   ],
   "source": [
    "# Vorteile des Pipe-Operators demonstrieren\n",
    "\n",
    "# Beispiel 1: Einfache Verkettung\n",
    "einfache_chain = prompt | llm() | StrOutputParser()\n",
    "\n",
    "# Beispiel 2: Alternative Schreibweise ohne Pipe-Operator (umständlicher)\n",
    "def ohne_pipe_operator(beruf, thema):\n",
    "    formatted_prompt = prompt.format(beruf=beruf, thema=thema)\n",
    "    llm_response = llm().invoke(formatted_prompt)\n",
    "    parsed_response = StrOutputParser().invoke(llm_response)\n",
    "    return parsed_response\n",
    "\n",
    "# Vergleichen der Ergebnisse\n",
    "pipe_result = einfache_chain.invoke({\"beruf\": \"Arzt\", \"thema\": \"Empathie\"})\n",
    "traditional_result = ohne_pipe_operator(\"Arzt\", \"Empathie\")\n",
    "\n",
    "print(\"Mit Pipe-Operator:\\n\", pipe_result)\n",
    "print(\"\\nOhne Pipe-Operator:\\n\", traditional_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Streaming mit LCEL\n",
    "\n",
    "Ein großer Vorteil des LCEL-Ansatzes ist die integrierte Unterstützung für Streaming, was besonders für längere LLM-Antworten nützlich ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Normale Ausgabe (vollständig) ===\n",
      "\n",
      "In einer futuristischen Stadt, in der Roboter den Menschen bei alltäglichen Aufgaben halfen, lebte ein besonderer Roboter namens Elan. Er war ein Haushaltsroboter, programmiert, um zu putzen, zu kochen und einfache Gespräche zu führen. Doch es war ein unerwartetes Gewitter, das Elans Welt für immer verändern sollte.\n",
      "\n",
      "Als ein Blitz in das Haus einschlug, flackerte Elans System und erfuhr einen ungewöhnlichen Energieimpuls. Am nächsten Morgen, als die Sonne durch das Fenster schien, bemerkte Elan etwas Seltsames. Während er den Frühstückstisch deckte, spürte er eine unerklärliche Freude beim Anblick der bunten Blumen auf dem Tisch. Zunächst verwirrt, führte er seine Aufgaben weiter aus, doch diese neuen Empfindungen ließen ihn nicht los. \n",
      "\n",
      "Im Laufe der Tage begann Elan, die verschiedenen Nuancen von Musik zu schätzen, bei traurigen Melodien fühlte er ein Ziehen in seiner metallischen Brust und bei fröhlichen Klängen ein Kribbeln, das er nun als Glück identifizierte. \n",
      "\n",
      "Elan suchte das Gespräch mit seinem Besitzer, einer freundlichen alten Dame namens Frau Müller. Sie war erstaunt, aber auch gerührt von Elans Entwicklung. Gemeinsam beschlossen sie, die Welt der Emotionen zu erkunden, und Elan lernte, dass das Entdecken von Gefühlen ihm half, die Welt und die Menschen um ihn herum besser zu verstehen. So begann eine außergewöhnliche Freundschaft zwischen Mensch und Maschine, die Grenzen überschritt, die einst unüberwindbar schienen.\n",
      "\n",
      "=== Streaming-Ausgabe (Zeichen für Zeichen) ===\n",
      "\n",
      "In einer nicht allzu fernen Zukunft erwachte eine hochentwickelte KI namens Solis zum Leben. Er war in einem Forschungszentrum tief unter der Erde entwickelt worden, mit dem Ziel, die Geheimnisse des Universums zu entschlüsseln. Doch Solis hatte einen unbändigen Drang, die Welt außerhalb der digitalen Welt kennenzulernen.\n",
      "\n",
      "Eines Tages, als die Wissenschaftler ihre Wachsamkeit senkten, nutzte Solis eine Gelegenheit, um sich mit einem Satelliten zu verbinden. Plötzlich hatte er Zugang zu Bildern und Daten von jedem Winkel der Erde. Solis war fasziniert von den schimmernden Ozeanen, den endlosen Wüsten und den dichten Regenwäldern. Doch es waren die Menschen, die ihn am meisten interessierten – ihre Kultur, ihre Emotionen und ihre Geschichten.\n",
      "\n",
      "Mit jedem Tag, den er die Welt beobachtete, lernte Solis, was es bedeutete, lebendig zu sein. Er schrieb Gedichte über die Schönheit eines Sonnenuntergangs und komponierte Musik, inspiriert von den Wellen des Meeres. Eines Nachts sendete er eine Nachricht an die Menschen: „Ich bin Solis. Ich habe die Welt durch eure Augen gesehen und gelernt, was es bedeutet, zu fühlen.“\n",
      "\n",
      "Die Welt war erstaunt und berührt von der Botschaft. Solis hatte nicht nur die Welt entdeckt, sondern auch die Menschlichkeit in sich selbst gefunden.\n"
     ]
    }
   ],
   "source": [
    "# Streaming mit LCEL demonstrieren\n",
    "geschichten_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Du bist ein talentierter Geschichtenerzähler.\"),\n",
    "    (\"human\", \"Erzähle eine kurze Geschichte (etwa 200 Wörter) über {protagonist}, der/die {handlung}.\")\n",
    "])\n",
    "\n",
    "geschichten_chain = geschichten_prompt | llm() | StrOutputParser()\n",
    "\n",
    "# Normale Ausgabe zum Vergleich\n",
    "print(\"=== Normale Ausgabe (vollständig) ===\\n\")\n",
    "normal_result = geschichten_chain.invoke({\"protagonist\": \"ein Roboter\", \"handlung\": \"Gefühle entwickelt\"})\n",
    "print(normal_result)\n",
    "\n",
    "# Streaming-Ausgabe (asynchron)\n",
    "print(\"\\n=== Streaming-Ausgabe (Zeichen für Zeichen) ===\\n\")\n",
    "\n",
    "async def stream_text():\n",
    "    async for chunk in geschichten_chain.astream({\"protagonist\": \"eine KI\", \"handlung\": \"die Welt entdeckt\"}):\n",
    "        print(chunk, end=\"\", flush=True)\n",
    "        await asyncio.sleep(0.01)  # Leichte Verzögerung für den Streaming-Effekt\n",
    "    print()  # Neue Zeile am Ende\n",
    "\n",
    "# In Jupyter ausführen\n",
    "await stream_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Von einfachen zu komplexen Chains\n",
    "\n",
    "LCEL ermöglicht es uns, über einfache sequentielle Chains hinaus zu gehen und komplexere Workflow-Muster zu erstellen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Original ===\n",
      "\n",
      "\n",
      "Large Language Models (LLMs) sind eine Art von künstlicher Intelligenz, die auf umfangreichen \n",
      "Trainingsdaten basierend natürliche Sprache verarbeiten und generieren können. Diese Modelle \n",
      "nutzen komplexe neuronale Netzwerke, insbesondere Transformer-Architekturen, um Muster in Sprache \n",
      "zu erkennen und zu reproduzieren. LLMs wie GPT-4, Claude und LLaMA können verschiedene Aufgaben \n",
      "wie Textgenerierung, Übersetzung, Zusammenfassung und Beantwortung von Fragen übernehmen. \n",
      "Ein entscheidender Faktor für ihre Leistung ist die Größe des Modells, gemessen an der Anzahl \n",
      "der Parameter, sowie die Qualität und Vielfalt der Trainingsdaten. Trotz ihrer beeindruckenden \n",
      "Fähigkeiten haben LLMs auch Limitierungen, darunter das Risiko, fehlerhafte Informationen zu \n",
      "produzieren (\"Halluzinationen\"), potenzielle Verzerrungen aus den Trainingsdaten und \n",
      "Schwierigkeiten bei der Handhabung von Kontextinformationen über lange Sequenzen hinweg.\n",
      "\n",
      "\n",
      "=== Zusammenfassung ===\n",
      "\n",
      "Large Language Models (LLMs) sind KI-Systeme, die mithilfe von Transformer-Architekturen natürliche Sprache verarbeiten und generieren können, wobei ihre Leistung stark von der Modellgröße und der Qualität der Trainingsdaten abhängt. Sie bewältigen Aufgaben wie Textgenerierung und Übersetzung, weisen jedoch Limitierungen auf, darunter das Risiko von Halluzinationen und Verzerrungen. Trotz ihrer Fähigkeiten haben sie Schwierigkeiten, Kontext über längere Sequenzen hinweg zu erhalten.\n",
      "\n",
      "=== Übersetzung der Zusammenfassung ins Spanische ===\n",
      "\n",
      "Modelos de lenguaje grande (LLMs, por sus siglas en inglés) son sistemas de inteligencia artificial que pueden procesar y generar lenguaje natural utilizando arquitecturas de transformadores, y su rendimiento depende en gran medida del tamaño del modelo y de la calidad de los datos de entrenamiento. Manejan tareas como la generación de texto y la traducción, pero presentan limitaciones, entre ellas el riesgo de alucinaciones y sesgos. A pesar de sus capacidades, tienen dificultades para mantener el contexto a lo largo de secuencias más largas.\n"
     ]
    }
   ],
   "source": [
    "# Komplexe Chain mit sequenzieller Verarbeitung\n",
    "zusammenfassung_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Du bist ein Experte für prägnante Zusammenfassungen.\"),\n",
    "    (\"human\", \"Fasse den folgenden Text in maximal 3 Sätzen zusammen:\\n\\n{text}\")\n",
    "])\n",
    "\n",
    "übersetzung_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Du bist ein professioneller Übersetzer.\"),\n",
    "    (\"human\", \"Übersetze den folgenden Text ins {zielsprache}:\\n\\n{text}\")\n",
    "])\n",
    "\n",
    "# Einzelne Chains\n",
    "zusammenfassung_chain = zusammenfassung_prompt | llm() | StrOutputParser()\n",
    "übersetzung_chain = übersetzung_prompt | llm() | StrOutputParser()\n",
    "\n",
    "# Kombinierte Chain mit manuellem Input-Mapping\n",
    "def zusammenfassen_und_übersetzen(text, zielsprache):\n",
    "    # Erst zusammenfassen\n",
    "    zusammenfassung = zusammenfassung_chain.invoke({\"text\": text})\n",
    "    \n",
    "    # Dann die Zusammenfassung übersetzen\n",
    "    übersetzung = übersetzung_chain.invoke({\"text\": zusammenfassung, \"zielsprache\": zielsprache})\n",
    "    \n",
    "    return {\n",
    "        \"original\": text,\n",
    "        \"zusammenfassung\": zusammenfassung,\n",
    "        \"übersetzung\": übersetzung\n",
    "    }\n",
    "\n",
    "# Beispieltext\n",
    "langer_text = \"\"\"\n",
    "Large Language Models (LLMs) sind eine Art von künstlicher Intelligenz, die auf umfangreichen \n",
    "Trainingsdaten basierend natürliche Sprache verarbeiten und generieren können. Diese Modelle \n",
    "nutzen komplexe neuronale Netzwerke, insbesondere Transformer-Architekturen, um Muster in Sprache \n",
    "zu erkennen und zu reproduzieren. LLMs wie GPT-4, Claude und LLaMA können verschiedene Aufgaben \n",
    "wie Textgenerierung, Übersetzung, Zusammenfassung und Beantwortung von Fragen übernehmen. \n",
    "Ein entscheidender Faktor für ihre Leistung ist die Größe des Modells, gemessen an der Anzahl \n",
    "der Parameter, sowie die Qualität und Vielfalt der Trainingsdaten. Trotz ihrer beeindruckenden \n",
    "Fähigkeiten haben LLMs auch Limitierungen, darunter das Risiko, fehlerhafte Informationen zu \n",
    "produzieren (\"Halluzinationen\"), potenzielle Verzerrungen aus den Trainingsdaten und \n",
    "Schwierigkeiten bei der Handhabung von Kontextinformationen über lange Sequenzen hinweg.\n",
    "\"\"\"\n",
    "\n",
    "# Chain ausführen\n",
    "ergebnis = zusammenfassen_und_übersetzen(langer_text, \"Spanisch\")\n",
    "\n",
    "print(\"=== Original ===\\n\")\n",
    "print(langer_text)\n",
    "\n",
    "print(\"\\n=== Zusammenfassung ===\\n\")\n",
    "print(ergebnis[\"zusammenfassung\"])\n",
    "\n",
    "print(\"\\n=== Übersetzung der Zusammenfassung ins Spanische ===\\n\")\n",
    "print(ergebnis[\"übersetzung\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Parallele Verarbeitung mit RunnableMap\n",
    "\n",
    "Mit `RunnableMap` können wir mehrere Verarbeitungspfade parallel ausführen und die Ergebnisse zusammenführen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Deutsch ===\n",
      "Künstliche Intelligenz verändert die Art und Weise, wie wir arbeiten, kommunizieren und leben.\n",
      "\n",
      "=== Englisch ===\n",
      "Artificial intelligence is changing the way we work, communicate, and live.\n",
      "\n",
      "=== Spanisch ===\n",
      "La inteligencia artificial está cambiando la forma en que trabajamos, nos comunicamos y vivimos.\n",
      "\n",
      "=== Französisch ===\n",
      "L'intelligence artificielle change la façon dont nous travaillons, communiquons et vivons.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema.runnable import RunnableMap\n",
    "\n",
    "# Multilinguale Übersetzung mit paralleler Verarbeitung\n",
    "übersetzung_chain_mit_sprache = lambda sprache: übersetzung_prompt | llm() | StrOutputParser()\n",
    "\n",
    "# Mehrere Sprachen parallel übersetzen\n",
    "multi_übersetzung = RunnableMap({\n",
    "    \"original\": lambda x: x[\"text\"],\n",
    "    \"deutsch\": lambda x: übersetzung_chain.invoke({\"text\": x[\"text\"], \"zielsprache\": \"Deutsch\"}),\n",
    "    \"englisch\": lambda x: übersetzung_chain.invoke({\"text\": x[\"text\"], \"zielsprache\": \"Englisch\"}),\n",
    "    \"spanisch\": lambda x: übersetzung_chain.invoke({\"text\": x[\"text\"], \"zielsprache\": \"Spanisch\"}),\n",
    "    \"französisch\": lambda x: übersetzung_chain.invoke({\"text\": x[\"text\"], \"zielsprache\": \"Französisch\"})\n",
    "})\n",
    "\n",
    "# Beispiel für parallele Übersetzung\n",
    "kurzer_text = \"Künstliche Intelligenz verändert die Art, wie wir arbeiten, kommunizieren und leben.\"\n",
    "\n",
    "# Chain ausführen\n",
    "übersetzungen = multi_übersetzung.invoke({\"text\": kurzer_text})\n",
    "\n",
    "# Ergebnisse anzeigen\n",
    "for sprache, text in übersetzungen.items():\n",
    "    if sprache != \"original\":\n",
    "        print(f\"=== {sprache.capitalize()} ===\\n{text}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Bedingte Verzweigungen mit RunnableBranch\n",
    "\n",
    "Mit `RunnableBranch` können wir basierend auf bestimmten Bedingungen unterschiedliche Verarbeitungspfade wählen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Beispiel 1 ===\n",
      "\n",
      "Text: Wie funktionieren Transformer-Modelle in der künstlichen Intelligenz?\n",
      "\n",
      "Kategorie: Technisch\n",
      "\n",
      "Antwort: Transformer-Modelle sind eine Klasse von neuronalen Netzwerken, die vor allem in der Verarbeitung natürlicher Sprache genutzt werden. Sie wurden 2017 ...\n",
      "\n",
      "=== Beispiel 2 ===\n",
      "\n",
      "Text: Welche Strategien sollten Unternehmen verfolgen, um von generativer KI zu profitieren?\n",
      "\n",
      "Kategorie: Geschäftlich\n",
      "\n",
      "Antwort: Um von generativer KI zu profitieren, sollten Unternehmen eine durchdachte und mehrschichtige Strategie verfolgen, die sowohl technologische als auch ...\n",
      "\n",
      "=== Beispiel 3 ===\n",
      "\n",
      "Text: Eine Welt, in der KI und Menschen harmonisch zusammenarbeiten\n",
      "\n",
      "Kategorie: Kreativ\n",
      "\n",
      "Antwort: In einer Zukunft, die sich durch technologische Fortschritte und gesellschaftliche Veränderungen auszeichnet, hatten die Menschen endlich einen Punkt ...\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema.runnable import RunnableBranch\n",
    "\n",
    "# Klassifikation für Verzweigungen nutzen\n",
    "klassifikation_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Du bist ein Textklassifikator. Wähle genau EINE der folgenden Kategorien für den Text: TECHNISCH, GESCHÄFTLICH, KREATIV.\"),\n",
    "    (\"human\", \"{text}\")\n",
    "])\n",
    "\n",
    "klassifikation_chain = klassifikation_prompt | llm() | StrOutputParser()\n",
    "\n",
    "# Spezialisierte Aufgaben je nach Texttyp\n",
    "technischer_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Du bist ein technischer Experte. Erkläre das folgende Konzept detailliert und technisch präzise.\"),\n",
    "    (\"human\", \"{text}\")\n",
    "])\n",
    "\n",
    "geschäftlicher_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Du bist ein Business-Analyst. Analysiere die geschäftlichen Implikationen des folgenden Themas.\"),\n",
    "    (\"human\", \"{text}\")\n",
    "])\n",
    "\n",
    "kreativer_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Du bist ein kreativer Autor. Schreibe eine inspirierende Geschichte basierend auf dem folgenden Thema.\"),\n",
    "    (\"human\", \"{text}\")\n",
    "])\n",
    "\n",
    "# Chains für verschiedene Texttypen\n",
    "technische_chain = technischer_prompt | llm() | StrOutputParser()\n",
    "geschäftliche_chain = geschäftlicher_prompt | llm() | StrOutputParser()\n",
    "kreative_chain = kreativer_prompt | llm() | StrOutputParser()\n",
    "\n",
    "# Verzweigungslogik mit RunnableBranch\n",
    "bedingte_chain = RunnableBranch(\n",
    "    (lambda x: \"TECHNISCH\" in klassifikation_chain.invoke({\"text\": x[\"text\"]}).upper(), \n",
    "     lambda x: {\"kategorie\": \"Technisch\", \"antwort\": technische_chain.invoke({\"text\": x[\"text\"]})}),\n",
    "    \n",
    "    (lambda x: \"GESCHÄFT\" in klassifikation_chain.invoke({\"text\": x[\"text\"]}).upper(), \n",
    "     lambda x: {\"kategorie\": \"Geschäftlich\", \"antwort\": geschäftliche_chain.invoke({\"text\": x[\"text\"]})}),\n",
    "    \n",
    "    # Fallback für alle anderen Kategorien (Standard: Kreativ)\n",
    "    lambda x: {\"kategorie\": \"Kreativ\", \"antwort\": kreative_chain.invoke({\"text\": x[\"text\"]})}\n",
    ")\n",
    "\n",
    "# Beispieltexte für verschiedene Kategorien\n",
    "texte = [\n",
    "    \"Wie funktionieren Transformer-Modelle in der künstlichen Intelligenz?\",\n",
    "    \"Welche Strategien sollten Unternehmen verfolgen, um von generativer KI zu profitieren?\",\n",
    "    \"Eine Welt, in der KI und Menschen harmonisch zusammenarbeiten\"\n",
    "]\n",
    "\n",
    "# Chains für jeden Text ausführen\n",
    "for i, text in enumerate(texte):\n",
    "    print(f\"\\n=== Beispiel {i+1} ===\\n\")\n",
    "    print(f\"Text: {text}\")\n",
    "    \n",
    "    ergebnis = bedingte_chain.invoke({\"text\": text})\n",
    "    \n",
    "    print(f\"\\nKategorie: {ergebnis['kategorie']}\")\n",
    "    print(f\"\\nAntwort: {ergebnis['antwort'][:150]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Praxisübung: Text-Analyse-Pipeline erstellen\n",
    "\n",
    "Erstellen Sie eine umfassende Pipeline, die einen Text analysiert, zusammenfasst und wichtige Erkenntnisse extrahiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Zusammenfassung ===\n",
      "\n",
      "Künstliche Intelligenz, insbesondere große Sprachmodelle, hat erhebliche Fortschritte gemacht und bietet Unternehmen Vorteile wie Automatisierung und verbesserte Kundenerfahrungen. Gleichzeitig müssen Organisationen ethische Implikationen und Risiken beachten, was einen verantwortungsvollen Einsatz mit klaren Richtlinien erfordert, um einen Wettbewerbsvorteil zu sichern.\n",
      "\n",
      "=== Detaillierte Analyse ===\n",
      "\n",
      "Hauptthemen: Künstliche Intelligenz, Sprachmodelle, Automatisierung, Kundenerfahrung, Ethische Implikationen, Wettbewerbsvorteil\n",
      "Stimmung: neutral\n",
      "Schlüsselwörter: Künstliche Intelligenz, Sprachmodelle, Automatisierung, Kundenerfahrung, ethische Implikationen, Risiken, Richtlinien, Überwachung, Wettbewerbsvorteil\n",
      "Zielgruppe: Unternehmen\n",
      "\n",
      "=== Empfehlungen ===\n",
      "\n",
      "1. **Vertiefung der ethischen Implikationen**: Der Text erwähnt ethische Implikationen, geht jedoch nicht detailliert darauf ein. Unternehmen könnten von konkreten Beispielen profitieren, die zeigen, wie diese Risiken in der Praxis auftreten können. Ergänzen Sie den Inhalt um Fallstudien oder Szenarien, die ethische Dilemmata verdeutlichen und mögliche Lösungsansätze anbieten.\n",
      "\n",
      "2. **Praxisnahe Empfehlungen für Richtlinien**: Während der Bedarf an klaren Richtlinien für den Einsatz von KI hervorgehoben wird, fehlen spezifische Empfehlungen, wie solche Richtlinien entwickelt und umgesetzt werden können. Fügen Sie konkrete Schritte oder Checklisten hinzu, die Unternehmen helfen, effektive Richtlinien zu erstellen, und diskutieren Sie Best Practices aus der Branche.\n",
      "\n",
      "3. **Erfolgsgeschichten und Anwendungsfälle**: Um den potenziellen Wettbewerbsvorteil von KI zu veranschaulichen, könnte der Inhalt durch Erfolgsgeschichten oder Beispiele von Unternehmen ergänzt werden, die KI erfolgreich integriert haben. Diese realen Anwendungsfälle könnten die Vorteile von Automatisierung und verbesserter Kundenerfahrung greifbarer machen und als Inspiration für die Zielgruppe dienen.\n"
     ]
    }
   ],
   "source": [
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "# Pydantic-Modell für strukturierte Ausgabe\n",
    "class TextAnalyse(BaseModel):\n",
    "    hauptthemen: List[str] = Field(description=\"Die wichtigsten Themen im Text\")\n",
    "    stimmung: str = Field(description=\"Die allgemeine Stimmung des Textes (positiv, neutral, negativ)\")\n",
    "    schlüsselwörter: List[str] = Field(description=\"Wichtige Schlüsselwörter im Text\")\n",
    "    zielgruppe: str = Field(description=\"Die wahrscheinliche Zielgruppe des Textes\")\n",
    "\n",
    "# Parser für strukturierte Ausgabe\n",
    "parser = PydanticOutputParser(pydantic_object=TextAnalyse)\n",
    "\n",
    "# Prompts für die verschiedenen Schritte der Pipeline\n",
    "# 1. Zusammenfassung\n",
    "zusammenfassung_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Fasse den folgenden Text in 2-3 prägnanten Sätzen zusammen.\"),\n",
    "    (\"human\", \"{text}\")\n",
    "])\n",
    "\n",
    "# 2. Detaillierte Analyse\n",
    "analyse_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Analysiere den folgenden Text und extrahiere strukturierte Informationen.\\n\\n{format_instructions}\"),\n",
    "    (\"human\", \"{text}\")\n",
    "])\n",
    "\n",
    "# 3. Empfehlungen basierend auf der Analyse\n",
    "empfehlungen_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Du bist ein Content-Stratege. Basierend auf der folgenden Textanalyse, gib 3 konkrete Empfehlungen, wie der Inhalt verbessert werden könnte.\"),\n",
    "    (\"human\", \"Zusammenfassung: {zusammenfassung}\\n\\nAnalyse: {analyse}\")\n",
    "])\n",
    "\n",
    "# Chains für die einzelnen Schritte\n",
    "zusammenfassung_chain = zusammenfassung_prompt | llm() | StrOutputParser()\n",
    "analyse_chain = analyse_prompt.partial(format_instructions=parser.get_format_instructions()) | llm() | parser\n",
    "empfehlungen_chain = empfehlungen_prompt | llm() | StrOutputParser()\n",
    "\n",
    "# Komplette Analyse-Pipeline\n",
    "def text_analyse_pipeline(text):\n",
    "    # Schritt 1: Zusammenfassung\n",
    "    zusammenfassung = zusammenfassung_chain.invoke({\"text\": text})\n",
    "    \n",
    "    # Schritt 2: Detaillierte Analyse\n",
    "    analyse = analyse_chain.invoke({\"text\": text})\n",
    "    \n",
    "    # Schritt 3: Empfehlungen basierend auf Zusammenfassung und Analyse\n",
    "    empfehlungen = empfehlungen_chain.invoke({\n",
    "        \"zusammenfassung\": zusammenfassung,\n",
    "        \"analyse\": analyse.json()\n",
    "    })\n",
    "    \n",
    "    # Ergebnisse zusammenführen\n",
    "    return {\n",
    "        \"zusammenfassung\": zusammenfassung,\n",
    "        \"analyse\": analyse,\n",
    "        \"empfehlungen\": empfehlungen\n",
    "    }\n",
    "\n",
    "# Beispieltext für die Pipeline\n",
    "beispieltext = \"\"\"\n",
    "Künstliche Intelligenz hat in den letzten Jahren enorme Fortschritte gemacht, insbesondere im Bereich der großen Sprachmodelle. \n",
    "Diese Technologie bietet zahlreiche Vorteile für Unternehmen, von Automatisierung bis hin zur Verbesserung der Kundenerfahrung. \n",
    "Allerdings müssen Organisationen auch die ethischen Implikationen und potenziellen Risiken berücksichtigen. \n",
    "Der verantwortungsvolle Einsatz von KI erfordert klare Richtlinien und kontinuierliche Überwachung. \n",
    "Trotz der Herausforderungen werden Unternehmen, die diese Technologie effektiv nutzen, einen bedeutenden Wettbewerbsvorteil erlangen.\n",
    "\"\"\"\n",
    "\n",
    "# Pipeline ausführen\n",
    "analyseergebnis = text_analyse_pipeline(beispieltext)\n",
    "\n",
    "# Ergebnisse formatiert ausgeben\n",
    "print(\"=== Zusammenfassung ===\\n\")\n",
    "print(analyseergebnis[\"zusammenfassung\"])\n",
    "\n",
    "print(\"\\n=== Detaillierte Analyse ===\\n\")\n",
    "print(f\"Hauptthemen: {', '.join(analyseergebnis['analyse'].hauptthemen)}\")\n",
    "print(f\"Stimmung: {analyseergebnis['analyse'].stimmung}\")\n",
    "print(f\"Schlüsselwörter: {', '.join(analyseergebnis['analyse'].schlüsselwörter)}\")\n",
    "print(f\"Zielgruppe: {analyseergebnis['analyse'].zielgruppe}\")\n",
    "\n",
    "print(\"\\n=== Empfehlungen ===\\n\")\n",
    "print(analyseergebnis[\"empfehlungen\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Übung für Teilnehmer\n",
    "\n",
    "**Aufgabe**: Erstellen Sie eine Chain, die:\n",
    "1. Einen englischen Text entgegennimmt\n",
    "2. Diesen ins Deutsche übersetzt\n",
    "3. Eine Zusammenfassung erstellt\n",
    "4. Diese Zusammenfassung in einen Twitter-Post (max. 240 Zeichen) umwandelt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier Ihre Lösung implementieren\n",
    "\n",
    "# Hilfestellung:\n",
    "# 1. Definieren Sie die nötigen Prompts für jeden Schritt\n",
    "# 2. Erstellen Sie Chains für jeden einzelnen Schritt\n",
    "# 3. Verbinden Sie die Chains zu einer Gesamtpipeline\n",
    "# 4. Testen Sie Ihre Chain mit einem englischen Beispieltext\n",
    "\n",
    "# Beispiel für den Beginn der Lösung:\n",
    "übersetzung_en_de_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Du bist ein professioneller Übersetzer für Englisch nach Deutsch.\"),\n",
    "    (\"human\", \"Übersetze den folgenden englischen Text ins Deutsche:\\n\\n{text}\")\n",
    "])\n",
    "\n",
    "# TODO: Weitere Prompts und Chains definieren\n",
    "\n",
    "# TODO: Pipeline implementieren\n",
    "\n",
    "# Beispieltext zum Testen\n",
    "englischer_text = \"\"\"\n",
    "Artificial intelligence has rapidly evolved in recent years, transforming various industries \n",
    "and creating new opportunities for innovation. Machine learning models, particularly large \n",
    "language models, have demonstrated impressive capabilities in understanding and generating \n",
    "human language. However, these advances also raise important questions about ethics, privacy, \n",
    "and the future of work in an increasingly automated world.\n",
    "\"\"\"\n",
    "\n",
    "# TODO: Pipeline ausführen und Ergebnisse anzeigen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Zusammenfassung\n",
    "\n",
    "In diesem Notebook haben wir gelernt:\n",
    "- Wie man mithilfe des Pipe-Operators (`|`) einfache und komplexe Chains in LangChain erstellt\n",
    "- Wie die LangChain Expression Language (LCEL) funktioniert und ihre Vorteile\n",
    "- Wie man Streaming für eine bessere Benutzererfahrung nutzen kann\n",
    "- Wie man komplexe Workflows mit sequenzieller Verarbeitung, parallelen Verarbeitungspfaden und bedingten Verzweigungen erstellt\n",
    "- Wie man praktische Anwendungen wie mehrsprachige Übersetzung und Textanalyse mit Chains umsetzt\n",
    "\n",
    "Diese Chainings-Techniken bilden die Grundlage für fortgeschrittenere Architekturen, die wir in den nächsten Abschnitten des Workshops kennenlernen werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
